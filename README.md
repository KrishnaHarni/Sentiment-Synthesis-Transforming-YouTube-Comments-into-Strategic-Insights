# Sentiment Synthesis Transforming YouTube Comments into Strategic Insights

This project analyzes YouTube video comments to automatically classify them as Positive, Negative, and Neutral using the XML-RoBERTa transformer model. It includes live comment extraction, text preprocessing, sentiment classification, and result visualization. The goal is to understand public sentiment on a large scale and provide insights into community feedback through a fully automated pipeline.

## ğŸš€ Features

- ğŸŒ **Flask-based website** to upload YouTube video links and view sentiment analysis results
- ğŸ” **Real-time comment extraction** from YouTube videos
- ğŸ§¹ **Text preprocessing** including tokenization, stopword removal, and lemmatization
- ğŸ¤– **Sentiment classification** using the XML-RoBERTa transformer model
- ğŸ“Š **Visualization of results** in bar charts and pie charts
- ğŸ’¾ Ability to store and analyze large volumes of data
- ğŸ“„ Detailed report generation for analysis

## ğŸ› ï¸ Tech Stack

- **Python**
- **Transformers (Hugging Face)**
- **Pandas & NumPy**
- **Matplotlib / Seaborn**
- **Scikit-learn**
- **Flask** 
- **Google Colab**

## ğŸ“¸ Screenshots

![image](https://github.com/user-attachments/assets/e9179e78-c50a-46f6-8f09-ca0ffee2ca1e)
![image](https://github.com/user-attachments/assets/c95d8add-7801-46b8-b0ba-78de8d733810) 
![image](https://github.com/user-attachments/assets/97e66114-444b-4492-9633-efff8e8f2855) 
![image](https://github.com/user-attachments/assets/1f2f759b-72b9-4e73-99b6-f9ce5c04387c)

## ğŸ¥ Video Presentation

Watch the project presentation video here: [View on Google Drive](https://drive.google.com/file/d/1bIwepdy4dO7A4P3xIvJBnNXmTkX646oD/view?usp=sharing)

## ğŸ“š Publication & Presentation
This project was completed as my Final Year Project and has been published in **International Research Journal on Advanced Engineering Hub (IRJAEH)** 2025. It was also presented at the **Second International Conference on Futuristic Trends in Science, Engineering, and Management (ICFTSEM -II) â€“ 2025**

You can read the full paper here: [https://irjaeh.com/index.php/journal/article/view/577/520]
